CatBoost（Categorical + Boosting）对于之前工作的几点改进或创新：
 - Categorical feature 的转换。**加入先验的均值编码**。加入先验可以减小样本数量较小的特征值转换偏差
 - 特征组合。使用数据的不同排列，每轮建树之前先掷骰子，决定使用哪个序列来生成树。在进行第一次节点分裂时，只考虑选择一个特征，在生成第二个节点时，
 考虑第一次选择的特征和和任意一个categorical特征的组合，选择其中最好的
 - **克服梯度偏差**。采用ordered boost的方法避免梯度估计的偏差，进而解决预测偏移的问题
 - 快速评分(预测效率高)。catboost使用**对称树**，一方面避免过拟合，另一方面大大加速预测
 
 
1. Categorical feature 的转换

 - 处理类别性特征的最常见方法是one_hot_encoding, 但该方法一方面存在特征丰富度较低，支持的特征运算有限；另一方面，当特征基数较大时，可能会有比较严重的特征稀疏问题，给存储和计算都带来很大麻烦。
一般在特征基数较小时会考虑one_hot_encoding方法。
 - 另一种常见的处理方法为均值编码，先计算每个类别型特征的取值样本的标签均值，然后将原类别取值替换为计算的均值，作为新的特征表示。
