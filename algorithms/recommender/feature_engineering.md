#### 1. 特征选择
 - 连续 -》 连续：相关分析。**图表可视化**；皮尔逊；协方差
 - 连续 -》 离散：方差分析；**连续特征离散化**后转换为：离散 -》 离散
 - 离散 -》 离散：卡方检验；互信息
 - 离散 -》 连续： **箱型图**；计算不同离散值下连续特征分布之间相关性的方法
 
 
#### 2. 连续特征的离散化
  在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为如一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：

 - 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展
 - **离散化后的特征对异常数据有很强的鲁棒性**：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰，但是**怎么划分区间是门学问**
 - 离散化后可以进行**特征交叉**，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力
 - 特征离散化以后，起到了简化了逻辑回归模型的作用，**降低了模型过拟合的风险**。
 
#### 3. 训练数据构建
 - **采样单位**。可以考虑**以用户为单位**进行采样，从而避免活跃用户的影响太大，造成模型训练不充分。
 - **正负样本选择**。正样本：点击。负样本比较复杂：物品曝光，并不一定代表用户注意到了，因此选择用户在推荐列表最下面的一个点击位置以上的曝光作为负样本区域，这样可以最大程度保证负样本是用户浏览过但没点击的物品。确定了正负样本之后，可以进行相关的负样本采样，比如设置**正负样本比例**为1：1或2：3等。
 - **样本冲突**。物品可以重复推荐，这样就存在用户选择前后矛盾的情况，即对于同一个物品上次用户选择点击，而这次选择不点击，或者反过来上次选择不点击，这次选择点击。对于一个时效性要求较高的系统，将这两种情况的数据都作为样本加入系统，可以增加模型对**时效性特征**的理解。由于用户可能某个时间段未关注、或者被其他物品干扰、或者某个时刻的心理状态等等问题存在。在宁缺毋滥的原则下，选择了一刀切去掉负样本的方式，即24小时之内，存在正负样本冲突的，仅保留正样本。同时如果24小时之内有多个负样本，仅保留最后也就是最新的负样本。
 - **特征穿越**。即**特征数据一定要选取样本发生时刻之前的**，如果选取或构建了样本时刻之后的特征，相当于在学习阶段，让模型知道了未来的行为特征，而真正的线上预测是不可能出现这种情况的。例如，样本点击是在下午，而构造训练样本是统一在凌晨，这时统计到的用户特征是包含点击之后的行为数据的。因此需要注意这一点，构造特征数据时考虑时间特征维度。
 
 #### 4. 推荐探索位
 推荐系统与热单都会倾向不再推质量较低的，大部分用户不太喜欢或者**曝光少**的的物品。长期会导致一些物品得不到曝光的机会，甚至彻底沉没。

为了解决该问题，增加了一个探索推荐位，强制抽选一个**该用户曝光最少的课程（曝光比例越低，被选中的概率越大，依概率随机采样）**，放在前十位推荐的课程中。该方法会在一定程度上降低点击率，但是会增加物品的整体曝光度，降低马太效应，提升推荐多样性和新颖性

#### 5. 接下来如何优化推荐效果
 - 召回阶段Embedding嵌入地理位置信息
 - 多任务学习尝试。样本标签构建时，虽然依然保留 0-1 CTR预估的标签，但是对于不同类型的点击行为如点赞、收藏、分享等，设置不同的样本权重，达到类似多任务学习的效果，为模型学习提供更丰富的标签信息
 - 主要还是结合业务情况多和产品沟通、多理解业务数据、多观察用户特点，暂时不会花更多精力研究更复杂的模型和算法
 
 
